#Centers.
Kmeans_3$centers
Kmeans_3
#Centers.
Kmeans_3$centers
#Within Group Sum of Squares.
Kmeans_3$withinss
#Clusters.
Kmeans_3$cluster
#Centers.
sum(Kmeans_3$centers)
#Centers.
Kmeans_3$centers
#Within Group Sum of Squares.
Kmeans_3$withinss
#Clusters.
Kmeans_3$cluster
head(Cluster_Ex)
Kmeans_3<-kmeans(Cluster_Ex,centers=3)
Kmeans_3
#Centers.
Kmeans_3$centers
#Within Group Sum of Squares.
Kmeans_3$withinss
#Clusters.
Kmeans_3$cluster
# Plotting clusters.
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_3$cluster,col=Kmeans_3$cluster)
#Adding centroids.
points(X2~X1,data=Kmeans_3$centers,pch=10,cex=1.8,col="blue")
Kmeans_3<-kmeans(Cluster_Ex,centers=5)
Kmeans_3
#Centers.
Kmeans_3$centers
Kmeans_3
#Centers.
Kmeans_3$centers
#Within Group Sum of Squares.
Kmeans_3$withinss
#Clusters.
Kmeans_3$cluster
# Plotting clusters.
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_3$cluster,col=Kmeans_3$cluster)
Kmeans_3<-kmeans(Cluster_Ex,centers=10)
Kmeans_3
#Centers.
Kmeans_3$centers
#Within Group Sum of Squares.
Kmeans_3$withinss
#Clusters.
Kmeans_3$cluster
# Plotting clusters.
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_3$cluster,col=Kmeans_3$cluster)
#Adding centroids.
points(X2~X1,data=Kmeans_3$centers,pch=10,cex=1.8,col="blue")
Kmeans_3<-kmeans(Cluster_Ex,centers=3)
Kmeans_3
#Centers.
Kmeans_3$centers
#Within Group Sum of Squares.
Kmeans_3$withinss
#Clusters.
Kmeans_3$cluster
# Plotting clusters.
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_3$cluster,col=Kmeans_3$cluster)
#Adding centroids.
points(X2~X1,data=Kmeans_3$centers,pch=10,cex=1.8,col="blue")
palette()
Kmeans_5_1<-kmeans(Cluster_Ex,centers=5)
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_5_1$cluster,col=Kmeans_5_1$cluster)
Kmeans_5_2<-kmeans(Cluster_Ex,centers=5)
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_5_2$cluster,col=Kmeans_5_2$cluster)
Kmeans_5_1<-kmeans(Cluster_Ex,centers=5)
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_5_1$cluster,col=Kmeans_5_1$cluster)
Kmeans_5_2<-kmeans(Cluster_Ex,centers=5)
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_5_2$cluster,col=Kmeans_5_2$cluster)
#using set seed for reproducibility.
Kmeans_5_3<-kmeans(Cluster_Ex,centers=Cluster_Ex[c(2,5,7,21,36),])
set.seed(5)
Kmeans_5_4<-kmeans(Cluster_Ex,centers=5)
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_5_4$cluster,col=Kmeans_5_4$cluster)
set.seed(6)
Kmeans_5_4<-kmeans(Cluster_Ex,centers=5)
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_5_4$cluster,col=Kmeans_5_4$cluster)
# Clustering with 3 clusters, nstart = 1. Randomize only once.
Cluster3_S1<-kmeans(Cluster_Ex,centers=3)
Cluster3_S50<-kmeans(Cluster_Ex,centers=3,nstart=50)
Cluster3_S1
Cluster3_S1$withinss
set.seed(6)
#using set seed for reproducibility.
Kmeans_5_3<-kmeans(Cluster_Ex,centers=Cluster_Ex[c(2,5,7,21,36),])
set.seed(6)
Kmeans_5_4<-kmeans(Cluster_Ex,centers=5)
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_5_4$cluster,col=Kmeans_5_4$cluster)
set.seed(5)
Kmeans_5_4<-kmeans(Cluster_Ex,centers=5)
plot(X2~X1,data=Cluster_Ex,xlim=c(0,4),ylim=c(0,4),cex.axis=1.3, cex.lab=1.2,cex=1.2,pch=15+Kmeans_5_4$cluster,col=Kmeans_5_4$cluster)
# Clustering with 3 clusters, nstart = 1. Randomize only once.
Cluster3_S1<-kmeans(Cluster_Ex,centers=3)
Cluster3_S50<-kmeans(Cluster_Ex,centers=3,nstart=50)
Cluster3_S1
Cluster3_S1$withinss
Cluster3_S1$tot.withinss
# Clustering with 3 clusters, nstart =50. Randomize 50 times.
Cluster3_S50
Cluster3_S50$withinss
Cluster3_S50$tot.withinss
Cluster3_S50$betweenss
# WGSS as a function of the number of clusters for values of K from 1 to 8.
wgss<-rep(0,8)
for(i in 1:8){wgss[i]<-kmeans(Cluster_Ex,centers=i,nstart=50)$tot.withinss}
plot(c(1:8),wgss,type="b",pch=16,cex=1.3,ylim=c(0,100), xlab="Number of Groups",ylab="WGSS")
# Clustering with 3 clusters, nstart =50. Randomize 50 times.
Cluster3_S50
Cluster3_S50$withinss
Cluster3_S50$tot.withinss
Cluster3_S50$betweenss
# WGSS as a function of the number of clusters for values of K from 1 to 8.
wgss<-rep(0,8)
for(i in 1:8){wgss[i]<-kmeans(Cluster_Ex,centers=i,nstart=50)$tot.withinss}
plot(c(1:8),wgss,type="b",pch=16,cex=1.3,ylim=c(0,100), xlab="Number of Groups",ylab="WGSS")
Kmeans_3$betweenss
# Clustering with 3 clusters, nstart = 1. Randomize only once.
Cluster3_S1<-kmeans(Cluster_Ex,centers=3)
Cluster3_S50<-kmeans(Cluster_Ex,centers=3,nstart=50)
Cluster3_S1
Cluster3_S1$withinss
Cluster3_S1$tot.withinss
# Clustering with 3 clusters, nstart =50. Randomize 50 times.
Cluster3_S50
Cluster3_S50$withinss
Cluster3_S50$tot.withinss
Cluster3_S50$betweenss
# WGSS as a function of the number of clusters for values of K from 1 to 8.
wgss<-rep(0,8)
for(i in 1:8){wgss[i]<-kmeans(Cluster_Ex,centers=i,nstart=50)$tot.withinss}
plot(c(1:8),wgss,type="b",pch=16,cex=1.3,ylim=c(0,100), xlab="Number of Groups",ylab="WGSS")
Kmeans_3$betweenss
# CH index.
chindex=c() # or rep(0,7)
# CH index.
chindex=c() # or rep(0,7)
i=1
for(k in 2:8){
chindex[i] <- (kmeans(df[2:3],k)$betweenss/(k-1))  / (kmeans(df[2:3],k)$tot.withinss/((nrow(df)-k)))
i=i+1
}
# CH index.
chindex=c() # or rep(0,7)
# CH index.
chindex=c() # or rep(0,7)
i=1
for(k in 2:8){
chindex[i] <- (kmeans(df[2:3],k)$betweenss/(k-1))  / (kmeans(df[2:3],k)$tot.withinss/((nrow(df)-k)))
i=i+1
}
plot(2:8,chindex,pch=19,type='b')
for(i in 1:8){wgss[i]<-kmeans(Cluster_Ex,centers=i,nstart=50)$tot.withinss}
# WGSS as a function of the number of clusters for values of K from 1 to 8.
wgss<-rep(0,8)
for(i in 1:8){wgss[i]<-kmeans(Cluster_Ex,centers=i,nstart=50)$tot.withinss}
plot(c(1:8),wgss,type="b",pch=16,cex=1.3,ylim=c(0,100), xlab="Number of Groups",ylab="WGSS")
---
title: "HW 7"
**Due date:** December 4 beginning of class.
```{r echo=FALSE}
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
# Custom options for knitting
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
fig.align = "center",
cache = FALSE
)
In this homework, we will analyze news headlines data scraped from abcnews, posted on Github in a csv file named `news.csv`.
Read the `news.csv` into R and create the object `news` using
```{r}
library(tidyverse)
library(dplyr) # I added this so it would knit properly
library(tm)
setwd("C:/Users/Peter/Documents/College Documents/DATA 180/Data 180 Peter Guma/DATA-180-PETER-GUMA/hw7")
news<-read.csv("news.csv",header=T)
library(tidyverse)
library(dplyr) # I added this so it would knit properly
library(tm)
setwd("C:/Users/Peter/Documents/College Documents/DATA 180/Data 180 Peter Guma/DATA-180-PETER-GUMA/hw7")
news<-read.csv("news.csv",header=T)
Read also the positive and negative word dictionaries, both found on Github. This will later come in handy:
```{r}
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
news<-read.csv("news.csv",header=T)
library(tm)
setwd("C:/Users/Peter/Documents/College Documents/DATA 180/Data 180 Peter Guma/DATA-180-PETER-GUMA/hw7")
news<-read.csv("news.csv",header=T)
library(tidyverse)
library(dplyr) # I added this so it would knit properly
library(tm)
setwd("C:/Users/Peter/Documents/College Documents/DATA 180/Data 180 Peter Guma/DATA-180-PETER-GUMA/hw7")
news<-read.csv("news.csv",header=T)
Read also the positive and negative word dictionaries, both found on Github. This will later come in handy:
```{r}
posWords <- scan("positive-words.txt", character(0), sep = "\n")  # 2006 items
negWords <- scan("negative-words.txt", character(0), sep = "\n")  # 4783 items
head(posWords,15)
head(negWords,15)
nrow(news)
charVector <- news$headline_text
head(charVector)
wordVector <- VectorSource(charVector)
wordCorpus <- Corpus(wordVector)
wordCorpus <- tm_map(wordCorpus, tolower)
wordCorpus <- tm_map(wordCorpus, removePunctuation)
wordCorpus <- tm_map(wordCorpus, removeNumbers)
wordCorpus <- tm_map(wordCorpus, removeWords, stopwords("en"))
tdm <- TermDocumentMatrix(wordCorpus)
m <- as.matrix(tdm)
wordCounts <- rowSums(m)
sortedWordCounts <- sort(wordCounts, decreasing = TRUE)
head(sortedWordCounts, n=10)
barplot(sortedWordCounts[sortedWordCounts>=50], ylab="Frequency", las=2, cex.names=.75, ylim=c(0,350), main="Words Appearing 50+ Times in News Headlines")
totalUnique = nrow(unique(m))
num_pos <- 0
num_neg <- 0
pos_match <- match(names(wordCounts), posWords, nomatch = 0)
pos_match <- pos_match != 0
pos_match <- wordCounts[pos_match]
pos_match
neg_match <- match(names(wordCounts), negWords, nomatch = 0)
neg_match <- neg_match != 0
neg_match <- wordCounts[neg_match]
neg_match
pct_pos <- sum(pos_match)/totalUnique
pct_neg <- sum(neg_match)/totalUnique
barplot(sort(pos_match[pos_match>=20], decreasing=TRUE), ylab="Frequency", las=2, ylim=c(0,80), main="Positive Words Appearing 20+ Times in Headlines")
barplot(sort(neg_match[neg_match>=20], decreasing=TRUE), ylab="Frequency", las=2, ylim=c(0,120), main="Negative Words Appearing 20+ Times in Headlines")
barplot(sort(neg_match[neg_match>=20], decreasing=TRUE), ylab="Frequency", las=2, ylim=c(0,120), main="Negative Words Appearing 20+ Times in Headlines")
pct_pos <- sum(pos_match)/totalUnique
pct_neg <- sum(neg_match)/totalUnique
barplot(sort(pos_match[pos_match>=20], decreasing=TRUE), ylab="Frequency", las=2, ylim=c(0,80), main="Positive Words Appearing 20+ Times in Headlines")
barplot(sort(neg_match[neg_match>=20], decreasing=TRUE), ylab="Frequency", las=2, ylim=c(0,120), main="Negative Words Appearing 20+ Times in Headlines")
news <- news %>% group_by(year,month) %>% mutate(count=n(), yearmonth = paste(year, month,sep = '/')) %>% arrange(year,month,day)
ggplot(news, aes(x=factor(yearmonth, levels = unique(yearmonth)))) + geom_bar() + theme(axis.text=element_text(size=4,angle=90))
newCharVector <- news$headline_text # had to put this here instead of in task 10 because otherwise it won't knit (no idea why)
library("quanteda")
```
topfeatures(dfm, n=20)
```
newCharVector <- news$headline_text # had to put this here instead of in task 10 because otherwise it won't knit (no idea why)
# aggregate(news, by=list(yearmonth=news$yearmonth), FUN=sum)
# ggplot(news, aes(x=news$yearmonth, y=news[])) + geom_bar()
# Old code for reference
```
```
dfm <- dfm(newCharVector, remove=stopwords("en"), remove_punct=TRUE, remove_symbols=TRUE)
topfeatures(dfm, n=20)
newCharVector <- news$headline_text # had to put this here instead of in task 10 because otherwise it won't knit (no idea why)
newCharVector <- news$headline_text
dfm <- dfm(newCharVector, remove=stopwords("en"), remove_punct=TRUE, remove_symbols=TRUE)
topfeatures(dfm, n=20)
dfm2 <- tokens_select(tokens(corpus(newCharVector), remove_symbols=TRUE, remove_punct=TRUE), pattern=stopwords("en"), selection="remove") %>%
tokens_ngrams(n = 2) %>%
dfm()
dfm2 <- tokens_select(tokens(corpus(newCharVector), remove_symbols=TRUE, remove_punct=TRUE), pattern=stopwords("en"), selection="remove") %>%
tokens_ngrams(n = 2) %>%
dfm()
topfeatures(dfm2, n=20)
newscorpus <- corpus(newCharVector)
newscorpus <- corpus_reshape(newscorpus, to="paragraphs") #unclear why this doesn't do anything
head(newscorpus)
news_dtm <- dfm(newCharVector, remove=stopwords("en"), remove_punct=TRUE, remove_symbols=TRUE, remove_numbers=TRUE)
# news_dtm <- tokens(corpus_subset(corpus(news_dtm), news_dtm[news_dtm>=50]))
# news_dtm <- news_dtm[>=50]
# news_dtm <- dfm_subset(news_dtm) # unsure how to manipulate this
head(news_dtm)
library("quanteda.textplots")
library("quanteda.textplots")
textplot_wordcloud(news_dtm)
library("topicmodels")
library('tidytext')
library("topicmodels")
library('tidytext')
topic_model <- LDA(news_dtm)
topic_model <- LDA(news_dtm, k=8)
topic_model
topfeatures(topic_model)
topic_model
View(topic_model)
topic_model <- LDA(news, k=8)
topic_model <- LDA(news$headline_text, k=8)
topic_model <- LDA(news_dtm, k=8)
top_n(topic_model, n=10)
topic_terms <- topic_model %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
topic_model <- LDA(news_dtm, k=8)
topic_terms <- topic_model %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
topic_terms <- topic_model %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
topic_model <- LDA(news_dtm, k=8)
topics <- tidy(topic_model, matrix = "beta")
library("reshape2")
library("reshape2")
topic_model <- LDA(news_dtm, k=8)
topic_terms <- topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
topic_model <- LDA(news_dtm, k=8)
topics <- tidy(topic_model, matrix = "beta")
topics
topic_terms <- topics %>%
group_by(topics$topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
topic_terms <- topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
topic_terms
View(topic_terms)
barplot(topic_terms)
topic_terms
barplot(topic_terms$topic)
barplot(topic_terms$beta)
barplot(topic_terms$beta, xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics")
topic_terms
barplot(group_by(topic_terms$beta, topic$termstopic), xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics")
barplot(group_by(topic_terms, topic$termstopic), xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics")
barplot(group_by(topic_terms, topic_terms$topic), xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics")
barplot(group_by(topic_terms$beta, topic_terms$topic), xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics")
barplot(topic_terms$beta, xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics")
barplot(topic_terms$beta, xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics", col=c(topic))
barplot(topic_terms$beta, xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics", col=c(topic_terms$topic))
barplot(topic_terms$beta, xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics", col=c(1,topic_terms$topic))
barplot(topic_terms$beta, xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics", col=c(2,topic_terms$topic))
barplot(topic_terms$beta, xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics", col=c(topic_terms$topic))
barplot(topic_terms_g$gamma)
topic_terms_g <- topics %>%
group_by(topic) %>%
top_n(10, gamma) %>%
ungroup() %>%
arrange(topic, -gamma)
topic_terms_g <- topics %>%
group_by(topic) %>%
top_n(10, gamma) %>%
ungroup() %>%
arrange(topic, -gamma)
topic_terms_g
topics_g <- tidy(topic_model, matrix = "gamma")
topics_g
topic_terms_g <- topics_g %>%
group_by(topic) %>%
top_n(10, gamma) %>%
ungroup() %>%
arrange(topic, -gamma)
topic_terms_g
barplot(topic_terms_g$gamma)
topics_g <- tidy(topic_model, matrix = "gamma")
topics_g
topic_terms_g <- topics_g %>%
group_by(topic) %>%
top_n(5, gamma) %>%
ungroup() %>%
arrange(topic, -gamma)
topic_terms_g
barplot(topic_terms$gamma, xlab="Top 5 Documents by Topic", ylab="Gamma", main="Top 10 Words with Highest Gamma for 8 Topics", col=c(topic_terms$topic))
barplot(topic_terms_g$gamma, xlab="Top 5 Documents by Topic", ylab="Gamma", main="Top 10 Words with Highest Gamma for 8 Topics", col=c(topic_terms$topic))
newscorpus <- corpus(newCharVector)
newscorpus <- corpus_reshape(newscorpus, to="paragraphs") #unclear why this doesn't do anything
head(newscorpus)
newscorpus <- corpus(newCharVector)
head(newscorpus)
newscorpus <- corpus_reshape(newscorpus, to="paragraphs") #unclear why this doesn't do anything
head(newscorpus)
newscorpus <- corpus(charVector)
newscorpus <- corpus_reshape(newscorpus, to="paragraphs") #unclear why this doesn't do anything
head(newscorpus)
newscorpus <- corpus(newCharVector)
newscorpus <- corpus_reshape(newscorpus, to="paragraphs") #unclear why this doesn't do anything
head(newscorpus)
newscorpus <- corpus(newCharVector)
head(newscorpus)
news <- news %>% group_by(year,month) %>% mutate(count=n(), yearmonth = paste(year, month,sep = '/')) %>% arrange(year,month,day)
ggplot(news, aes(x=factor(yearmonth, levels = unique(yearmonth)))) + geom_bar() + theme(axis.text=element_text(size=4,angle=90))
library("quanteda")
newCharVector <- news$headline_text
dfm <- dfm(newCharVector, remove=stopwords("en"), remove_punct=TRUE, remove_symbols=TRUE)
topfeatures(dfm, n=20)
dfm2 <- tokens_select(tokens(corpus(newCharVector), remove_symbols=TRUE, remove_punct=TRUE), pattern=stopwords("en"), selection="remove") %>%
tokens_ngrams(n = 2) %>%
dfm()
topfeatures(dfm2, n=20)
newscorpus <- corpus(newCharVector)
newscorpus <- corpus_reshape(newscorpus, to="paragraphs") #unclear why this doesn't do anything
head(newscorpus)
news_dtm <- dfm(newCharVector, remove=stopwords("en"), remove_punct=TRUE, remove_symbols=TRUE, remove_numbers=TRUE)
# news_dtm <- tokens(corpus_subset(corpus(news_dtm), news_dtm[news_dtm>=50]))
# news_dtm <- news_dtm[>=50]
# news_dtm <- dfm_subset(news_dtm) # unsure how to manipulate this
head(news_dtm)
news_dtm <- dfm(newCharVector, remove=stopwords("en"), remove_punct=TRUE, remove_symbols=TRUE, remove_numbers=TRUE, stem=TRUE)
# news_dtm <- tokens(corpus_subset(corpus(news_dtm), news_dtm[news_dtm>=50]))
# news_dtm <- news_dtm[>=50]
# news_dtm <- dfm_subset(news_dtm) # unsure how to manipulate this
head(news_dtm)
# news_dtm <- tokens(corpus_subset(corpus(news_dtm), news_dtm[news_dtm>=50]))
# news_dtm <- news_dtm[>=50]
# news_dtm <- dfm_subset(news_dtm) # unsure how to manipulate this
dfm_trim(news_dtm, min_termfreq = 50)
# news_dtm <- tokens(corpus_subset(corpus(news_dtm), news_dtm[news_dtm>=50]))
# news_dtm <- news_dtm[>=50]
# news_dtm <- dfm_subset(news_dtm) # unsure how to manipulate this
dfm_trim(news_dtm, min_termfreq = 50)
# news_dtm <- tokens(corpus_subset(corpus(news_dtm), news_dtm[news_dtm>=50]))
# news_dtm <- news_dtm[>=50]
# news_dtm <- dfm_subset(news_dtm) # unsure how to manipulate this
news_dtm <- dfm_trim(news_dtm, min_termfreq = 50)
head(news_dtm)
library("quanteda.textplots")
textplot_wordcloud(news_dtm)
library("topicmodels")
library('tidytext')
library("reshape2")
topic_model <- LDA(news_dtm, k=8)
topics <- tidy(topic_model, matrix = "beta")
topics
topic_terms <- topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
topic_terms
barplot(topic_terms$beta, xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics", col=c(topic_terms$topic))
# barplot(topic_terms$beta, xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics", col=c(topic_terms$topic))
news_top_topics %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered()
# barplot(topic_terms$beta, xlab="Top 10 Words by Topic", ylab="Beta", main="Top 10 Words with Highest Beta for 8 Topics", col=c(topic_terms$topic))
topic_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered()
# barplot(topic_terms_g$gamma, xlab="Top 5 Documents by Topic", ylab="Gamma", main="Top 5 Documents with Highest Gamma for 8 Topics", col=c(topic_terms$topic))
# wrong number of documents
topic_terms_g %>%
mutate(term = reorder_within(term, gamma, topic)) %>%
ggplot(aes(gamma, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered()
# barplot(topic_terms_g$gamma, xlab="Top 5 Documents by Topic", ylab="Gamma", main="Top 5 Documents with Highest Gamma for 8 Topics", col=c(topic_terms$topic))
# wrong number of documents
topic_terms_g %>%
mutate(document = reorder_within(term, gamma, topic)) %>%
ggplot(aes(gamma, document, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered()
# barplot(topic_terms_g$gamma, xlab="Top 5 Documents by Topic", ylab="Gamma", main="Top 5 Documents with Highest Gamma for 8 Topics", col=c(topic_terms$topic))
# wrong number of documents
topic_terms_g %>%
mutate(document = reorder_within(document, gamma, topic)) %>%
ggplot(aes(gamma, document, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered()
topic_model <- LDA(news_dtm, k=8)
topic_model <- LDA(news_dtm, k=8)
news_dtm <- dfm(newCharVector, remove=stopwords("en"), remove_punct=TRUE, remove_symbols=TRUE, remove_numbers=TRUE, stem=TRUE)
news_dtm <- dfm_trim(news_dtm, min_termfreq = 50)
head(news_dtm)
library("quanteda.textplots")
textplot_wordcloud(news_dtm)
library("topicmodels")
library('tidytext')
library("reshape2")
topic_model <- LDA(news_dtm, k=8)
View(news_dtm)
topics <- tidy(topic_model, matrix = "beta")
topics
topic_terms <- topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
topic_model <- LDA(news_dtm, k=8)
